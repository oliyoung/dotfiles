= Subway Digital Menu Board Integration - Solution Architecture
:project-name: Subway Digital Menu Board Integration
:togaf-adm-phase: Phase E: Opportunities & Solutions
:last-updated: 2026-01-13
:document-type: Solution Architecture Document
:status: Development
:version: 0.1
:domain: ProductCatalog
:programme-lead: TBD
:domain-architect: O.Young@otr.com.au
:architecture-definition: xref:architecture-definitions:subway_dmb.adoc[Architecture Definitions/Subway DMB Integration]
:doctype: article
:toc: left
:toclevels: 4
:sectanchors:
:sectlinks:
:sectnums:
:icons: font
:source-highlighter: highlightjs
:experimental:
:description:
:keywords:

<<<
== Purpose and Scope

=== Purpose

This Solution Architecture defines how the Subway Digital Menu Board pricing integration will be implemented - the specific technology products, configurations, interfaces, and deployment architecture that realise the xref:architecture-definitions:subway_dmb.adoc[Subway DMB Integration Architecture Definition].

This solution establishes the **first cross-cloud domain integration pattern** for OTR Group by deploying the xref:bounded-contexts:product_catalog.adoc[ProductCatalogService] bounded context, implementing cross-cloud data synchronisation (Azure ↔ AWS), and establishing patterns that will serve as the foundation for future product catalog consumers (mobile app, online ordering).

=== Vision

> Enable accurate, automated pricing display on Subway digital menu boards across all OTR-operated stores by establishing a cross-cloud product catalog integration that bridges back-office systems (D365 Commerce on Azure) with customer-facing digital experiences (AWS), creating a scalable foundation for future ecommerce product catalog capabilities.

=== Architectural Approach

This architecture establishes OTR's **first cross-cloud integration pattern** using the following approach:

* *xref:bounded-contexts:product_catalog.adoc[ProductCatalogService]* (NEW bounded context): Product catalog and pricing facade, ingests pricing from D365 Commerce via S3, provides RESTful API for DMB platform, AWS-native implementation (Lambda/ECS, RDS PostgreSQL, S3, API Gateway)
* *Cross-Cloud Data Pipeline* (NEW pattern): S3-based data contract for cross-cloud integration (Azure → AWS), hourly/daily scheduled sync, foundation for future back-office data integrations
* *Anti-Corruption Layer*: ProductCatalogService translates D365 Commerce product model into OTR domain language, protects ecommerce domain from back-office system changes
* *Conformist Pattern*: ProductCatalogService conforms to D365 Commerce data contract (external system we don't control)
* *Phased rollout*: Pilot stores validation before full rollout

=== Scope

==== In Scope

* Solution Building Blocks (SBBs) - specific technology products and versions
* Interface specifications (REST API, data formats)
* Data architecture and database schema specifications
* Deployment architecture and AWS infrastructure configuration
* Transition architecture with implementation phases
* Technical validation criteria and testing approach
* External system integration specifications (D365 Commerce, Amped Digital)
* Cross-cloud data synchronisation pipeline

==== Out of Scope

===== Covered in xref:architecture-definitions:subway_dmb.adoc[Architecture Definition]

* Business requirements and stakeholder analysis
* Architecture decisions and rationale (ADRs)
* Bounded context definitions and responsibilities
* High-level integration patterns (ACL, Conformist, BFF)
* Business capability mapping and value streams
* Architecture principles and governance

===== Covered in Other Documents

* Detailed design (class diagrams, sequence diagrams for all flows)
* Implementation code and unit tests
* Business case and return-on-investment analysis
* Operational run books and support procedures

<<<
=== Architecture Overview

== Phase E: Opportunities and Solutions

=== Solution Architecture Overview

[mermaid]
----
graph TB
    subgraph "Solution Components"
        direction TB
        A[Data Ingestion Layer<br/>AWS] --> B[Data Storage Layer<br/>AWS]
        B --> C[API Service Layer<br/>AWS]
        C --> D[Integration Layer]
    end

    subgraph "Data Ingestion Layer (AWS)"
        E[S3 Event Trigger]
        F[ETL Pipeline<br/>Glue/Lambda]
        G[Data Validation]
        H[Error Handling]
        E --> F --> G
        G -->|Success| I[Load to RDS]
        G -->|Failure| H
        H --> J[SNS Alert]
    end

    subgraph "Data Storage Layer (AWS)"
        I --> K[RDS PostgreSQL]
        K --> L[Products Table]
        K --> M[Prices Table]
        K --> N[Price Groups Table]
        K --> O[Stores Table]
    end

    subgraph "API Service Layer (AWS)"
        P[API Gateway]
        Q[ECS Service<br/>Pricing API]
        R[Redis Cache<br/>Optional]
        P --> Q
        Q -.->|Cache Hit| R
        Q -->|Cache Miss| K
    end

    subgraph "Integration Layer"
        S[Amped Digital<br/>DMB Platform]
        T[Future Consumer<br/>OTR App]
        U[Future Consumer<br/>SMGB Online]
        P --> S
        P -.->|Future| T
        P -.->|Future| U
    end
----

=== Implementation Phases

==== Phase 1: Foundation

*Duration:* Weeks 1-2

*Activities:*

* Define data contract with back-office team
* Set up S3 bucket with cross-account IAM access (Azure → AWS)
* Provision RDS PostgreSQL instance
* Create database schema

*Deliverables:*

* Data contract specification document
* S3 bucket configured with cross-account access
* RDS instance provisioned and secured
* Database schema DDL scripts

==== Phase 2: Data Pipeline

*Duration:* Weeks 2-4

*Activities:*

* Build ETL pipeline (Glue/Lambda)
* Implement data validation logic
* Set up error handling and alerting (SNS, CloudWatch)
* Test with sample data from back-office

*Deliverables:*

* ETL pipeline code (Glue job or Lambda function)
* Data validation rules implemented
* CloudWatch alarms configured
* SNS notification setup for failures

==== Phase 3: API Development

*Duration:* Weeks 4-6

*Activities:*

* Build REST API service (ECS container)
* Implement OAuth 2.0 authentication
* Add caching layer (API Gateway cache or ElastiCache)
* API documentation (OpenAPI spec)

*Deliverables:*

* API service containerized and deployed to ECS
* OAuth 2.0 authentication implemented
* API Gateway configured with caching
* OpenAPI specification document

==== Phase 4: Integration & Testing

*Duration:* Weeks 6-7

*Activities:*

* Integrate with Amped Digital (provide credentials)
* End-to-end testing with production-like data
* Performance testing (load, stress)
* Security testing (penetration test)

*Deliverables:*

* Amped Digital credentials provisioned
* Test results documentation
* Performance test report
* Security test report

==== Phase 5: Production Launch

*Duration:* Week 8

*Activities:*

* Deploy to production (AWS)
* Monitor for 48 hours
* Knowledge transfer to ecommerce operations team
* Document runbooks

*Deliverables:*

* Production deployment complete
* Monitoring dashboards configured
* Operations runbooks documented
* Team training completed

---

== Phase F: Migration Planning

=== Current State → Target State

*Current State:*

* No integration exists
* Amped Digital has no pricing data
* Manual price updates to menu boards (assumed)

*Target State:*

* Automated pricing feed on AWS
* Hourly updates
* Self-service API for vendor
* Scalable pattern for future ecommerce integrations

*Migration Strategy:* Greenfield implementation (no legacy to migrate)

=== Cutover Plan

. Deploy API to production (AWS)
. Provide Amped Digital with credentials and endpoint
. Parallel testing (vendor tests against API while using old process)
. Cutover: Vendor switches to API feed
. Monitor for 1 week, retire old process

=== Rollback Strategy

If critical issues arise during cutover:

. Vendor reverts to previous manual process
. Investigate and fix issues in non-production environment
. Schedule new cutover date after fixes verified

---

== Phase G: Implementation Governance

=== Roles & Responsibilities

[cols="2,3,2,2"]
|===
|Role |Responsibility |Individual/Team |Domain

|*Solution Architect*
|Architecture design, technology decisions
|Oli (O.Young@otr.com.au)
|Ecommerce (AWS)

|*Back-Office Data Lead*
|Data contract delivery, Azure-side implementation
|MJ / Grant's team
|Back-Office (Azure)

|*Development Team Lead*
|AWS implementation, code delivery
|[TBD - ecommerce team]
|Ecommerce (AWS)

|*DevOps Engineer*
|AWS infrastructure provisioning, CI/CD
|[TBD - ecommerce team]
|Ecommerce (AWS)

|*QA Lead*
|Testing strategy, test execution
|[TBD - ecommerce team]
|Ecommerce (AWS)

|*Product Owner*
|Requirements, vendor coordination
|[TBD - business]
|Business

|*Operations Team*
|Production support, monitoring (AWS)
|[TBD - ecommerce team]
|Ecommerce (AWS)
|===

*Key Point:* Ecommerce team owns all AWS components. Back-office team only responsible for delivering data to S3.

=== Risk Register

[cols="2,1,3,2"]
|===
|Risk |Likelihood |Impact |Mitigation

|Cross-cloud data transfer failures
|Medium
|High - No pricing updates
|Implement retry logic, alerting, fallback to last known good data

|D365 schema changes breaking ETL
|Medium
|High - Data pipeline failure
|Data contract with versioning, schema validation, back-office notification process

|API performance degradation
|Low
|Medium - Slow responses
|Implement caching, load testing, auto-scaling, performance monitoring

|Amped Digital authentication issues
|Medium
|Medium - Integration failure
|Credential rotation process, monitoring, clear escalation path

|S3 bucket misconfiguration
|Low
|High - Data exposure or access failure
|Infrastructure as Code, security reviews, least privilege IAM policies

|RDS capacity issues
|Low
|Medium - Database performance
|Right-sizing, monitoring, read replicas, auto-scaling storage
|===

=== Quality Gates

[cols="1,3,2"]
|===
|Phase |Quality Criteria |Approval Required

|Foundation
|• Data contract signed off +
• S3 access verified +
• RDS connectivity tested
|Back-Office Lead, Security Architect

|Data Pipeline
|• ETL successfully processes test data +
• Validation rules verified +
• Alerting working
|Development Lead, QA Lead

|API Development
|• API meets OpenAPI spec +
• Authentication working +
• Performance < 500ms p95
|Solution Architect, Security Architect

|Integration & Testing
|• End-to-end test passed +
• Load test passed (1000 req/hr) +
• Security test passed
|QA Lead, Security Architect, Product Owner

|Production Launch
|• Deployment successful +
• Monitoring dashboards live +
• Runbooks documented
|Operations Lead, Product Owner
|===

---

== Phase H: Architecture Change Management

=== Non-Functional Requirements

[cols="2,2,3"]
|===
|Requirement |Target |Measurement

|*Availability*
|99.9% uptime
|CloudWatch uptime metric

|*Performance*
|API response < 500ms p95
|API Gateway latency metric

|*Scalability*
|Support 1000 req/hour
|Load testing validation

|*Data Freshness*
|Updates within 1 hour
|ETL completion time metric

|*Security*
|Zero unauthorised access
|CloudTrail audit, WAF blocks

|*Recoverability*
|RTO: 1 hour, RPO: 1 hour
|DR testing validation
|===

=== Monitoring & Observability

[mermaid]
----
graph TB
    subgraph "Observability Stack (AWS)"
        A[Application Logs] --> B[CloudWatch Logs]
        C[Metrics] --> D[CloudWatch Metrics]
        E[Traces] --> F[X-Ray]
        G[Events] --> H[EventBridge]

        B --> I[CloudWatch Dashboard]
        D --> I
        F --> I

        I --> J{Threshold Breach?}
        J -->|Yes| K[SNS Topic]
        K --> L[PagerDuty]
        K --> M[Slack Channel]
        K --> N[Email]
    end

    subgraph "Key Metrics"
        O[API Latency]
        P[API Error Rate]
        Q[ETL Success/Failure]
        R[RDS CPU/Memory]
        S[Data Freshness]
    end
----

==== Alerting Rules

[cols="3,1,3"]
|===
|Alert Condition |Priority |Action

|API error rate > 1% for 5 minutes
|P1
|Page on-call engineer immediately

|API latency p95 > 1s for 5 minutes
|P2
|Notify operations team

|ETL job failure
|P1
|Page on-call engineer + notify back-office team

|RDS CPU > 80% for 10 minutes
|P2
|Notify operations team

|No new data in S3 for 90 minutes
|P2
|Notify back-office team
|===

=== Key Metrics Dashboard

*Real-Time Metrics:*

* API requests per minute
* API latency (p50, p95, p99)
* API error rate
* Cache hit ratio
* RDS connections
* RDS CPU/Memory utilisation

*Batch Metrics:*

* ETL job execution time
* Records processed per run
* Data validation failures
* S3 file size trends

---

== Deployment Architecture

=== AWS Infrastructure

[mermaid]
----
graph TB
    subgraph "AWS Region: ap-southeast-2"
        subgraph "VPC: otr-ecommerce"
            subgraph "Public Subnet"
                ALB[Application Load Balancer]
                NAT[NAT Gateway]
            end

            subgraph "Private Subnet A"
                ECS1[ECS Task<br/>API Container 1]
                RDS1[(RDS Primary<br/>PostgreSQL)]
            end

            subgraph "Private Subnet B"
                ECS2[ECS Task<br/>API Container 2]
                RDS2[(RDS Standby<br/>Read Replica)]
            end

            subgraph "Isolated Subnet"
                GLUE[Glue Job<br/>ETL Pipeline]
            end
        end

        S3[S3 Bucket<br/>Pricing Exports]
        API[API Gateway]

        S3 --> GLUE
        GLUE --> RDS1
        RDS1 -.->|Replication| RDS2
        API --> ALB
        ALB --> ECS1
        ALB --> ECS2
        ECS1 --> RDS1
        ECS2 --> RDS2
    end

    EXT[Amped Digital] -->|HTTPS| API

    AZURE[Azure Back-Office] -.->|Cross-Cloud Export| S3
----

=== Infrastructure as Code

*Technology:* AWS CloudFormation or Terraform

*Components:*

* VPC and networking (subnets, security groups, NACLs)
* S3 bucket with cross-account access policy
* RDS PostgreSQL instance with encryption
* ECS cluster, service, and task definitions
* API Gateway configuration
* CloudWatch alarms and dashboards
* IAM roles and policies

*Repository Structure:*

----
infrastructure/
├── network/              # VPC, subnets, security groups
├── storage/              # S3 buckets, RDS instances
├── compute/              # ECS clusters, task definitions
├── api/                  # API Gateway configuration
├── monitoring/           # CloudWatch alarms, dashboards
└── iam/                  # IAM roles, policies
----

---

== Appendices

=== Appendix A: API Specification

*Endpoint:* `GET /api/v1/pricing`

*Authentication:* OAuth 2.0 Bearer Token (Client Credentials flow)

*Response Format:*

[source,json]
----
{
  "generated_at": "2025-01-13T10:30:00Z",
  "products": [
    {
      "product_number": "398602",
      "product_name": "Italian BMT Footlong",
      "price": [
        {
          "account_relation": "POS-AU-NAT",
          "amount": "14.40",
          "stores": [19598, 20260, 20334]
        },
        {
          "account_relation": "POS-SA-R",
          "amount": "14.90",
          "stores": [21522, 25155, 26112]
        }
      ]
    }
  ]
}
----

*Response Codes:*

* 200: Success
* 401: Unauthorised (invalid/expired token)
* 429: Too Many Requests (rate limit exceeded)
* 500: Internal Server Error
* 503: Service Unavailable

*Rate Limiting:* 100 requests per hour per client

=== Appendix B: Data Contract Details

*S3 Bucket Configuration:*

* *Bucket Name:* `otr-pricing-exports-prod`
* *Region:* `ap-southeast-2` (Sydney)
* *Path Pattern:* `/subway/YYYY/MM/DD/pricing_YYYYMMDDHHmmss.parquet`
* *File Format:* Apache Parquet
* *Compression:* Snappy
* *Encryption:* SSE-S3

*Cross-Account Access:*

* Back-office Azure account can write to S3 via IAM role
* Ecommerce AWS account owns the bucket
* Bucket policy restricts access to specific Azure service principal

=== Appendix C: Runbooks

==== Runbook: ETL Failure

*Symptom:* ETL job fails, no new pricing data loaded

*Investigation Steps:*

. Check CloudWatch Logs for ETL job error details
. Verify S3 file exists at expected path
. Verify file format and schema validity
. Check RDS connectivity from Glue/Lambda
. Review IAM role permissions

*Resolution:*

* If transient failure (network, timeout): Retry job manually
* If data quality issue: Contact back-office team
* If schema change: Update ETL transformation logic
* If RDS connectivity: Check security groups, network ACLs

*Escalation:* Back-office team if data source issue; Infrastructure team if AWS service issue

==== Runbook: API High Latency

*Symptom:* API response time > 1 second p95

*Investigation Steps:*

. Check CloudWatch metrics for RDS CPU/memory
. Check API Gateway metrics for integration latency
. Review RDS slow query logs
. Check cache hit rate
. Review ECS task metrics

*Resolution:*

* If RDS constrained: Scale instance vertically or add read replicas
* If slow queries: Add indexes, optimise queries
* If cache ineffective: Increase cache TTL or implement ElastiCache
* If ECS constrained: Scale out tasks

*Escalation:* Database team if persistent query performance issues

==== Runbook: Authentication Failures

*Symptom:* 401 errors from API Gateway

*Investigation Steps:*

. Verify client credentials in Secrets Manager
. Check API Gateway authoriser CloudWatch logs
. Verify OAuth token expiry and refresh
. Check for recent credential rotation

*Resolution:*

* If expired credentials: Provide new credentials to Amped Digital
* If authoriser misconfigured: Review Lambda authoriser logic
* If Secrets Manager issue: Verify IAM permissions

*Escalation:* Security team if credential compromise suspected

==== Runbook: No New Data in S3

*Symptom:* S3 bucket has no new files for > 90 minutes

*Investigation Steps:*

. Contact back-office team to verify export job status
. Check Azure Data Factory / Fabric logs
. Verify cross-account IAM role is valid
. Check S3 bucket policy hasn't changed

*Resolution:*

* If Azure export job failed: Back-office team to investigate and re-run
* If IAM role expired: Update cross-account access configuration
* If bucket policy changed: Restore correct policy

*Escalation:* Back-office team for Azure-side issues; Security team for IAM issues

---

== Document Control

[cols="1,2,2,4"]
|===
|Version |Date |Author |Changes

|0.1
|2025-01-13
|O.Young (Domain Architect, Ecommerce)
|Initial draft - Phases E, F, G, H
|===

*Approval Required From:*

* [ ] Development Lead (confirms implementation approach)
* [ ] DevOps Lead (confirms infrastructure design)
* [ ] Operations Lead (confirms runbooks and monitoring)
* [ ] Product Owner (confirms delivery timeline)
